{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Indic NLP Library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the _Indic NLP Library_ is to build Python based libraries for common text processing and Natural Language Processing in Indian languages. Indian languages share a lot of similarity in terms of script, phonology, language syntax, etc. and this library is an attempt to provide a general solution to very commonly required toolsets for Indian language text. \n",
    "\n",
    "The library provides the following functionalities: \n",
    "\n",
    "- Text Normalization\n",
    "- Script Information\n",
    "- Tokenization\n",
    "- Word Segmenation\n",
    "- Script Conversion\n",
    "- Romanization\n",
    "- Indicization\n",
    "- Transliteration\n",
    "- Translation\n",
    "\n",
    "The data resources required by the Indic NLP Library are hosted in a different repository. These resources are required for some modules. You can download from the [Indic NLP Resources](https://github.com/anoopkunchukuttan/indic_nlp_resources) project.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "- Python 2.7+\n",
    "- [Morfessor 2.0 Python Library](http://www.cis.hut.fi/projects/morpho/morfessor2.shtml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  ----- Set these variables -----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The path to the local git repo for Indic NLP library\n",
    "INDIC_NLP_LIB_HOME=\"/home/anoop/src/python/indic_nlp_library\"\n",
    "# The path to the local git repo for Indic NLP Resources\n",
    "INDIC_NLP_RESOURCES=\"/home/anoop/installs/indic_nlp_resources\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Library to Python path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('{}/src'.format(INDIC_NLP_LIB_HOME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Export environment variable ** \n",
    "\n",
    "    export INDIC_RESOURCES_PATH=<path>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     OR\n",
    "     \n",
    "**set it programmatically**\n",
    "We will use that method for this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from indicnlp import common\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Initialize the Indic NLP library **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from indicnlp import loader\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###_Let's actually try out some of the APIs in the Indic NLP library_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Text Normalization\n",
    "\n",
    "Text written in Indic scripts display a lot of quirky behaviour on account of varying input methods, multiple representations for the same character, etc. \n",
    "There is a need to canonicalize the representation of text so that NLP applications can handle the data in a consistent manner. The canonicalization primarily handles the following issues: \n",
    "\n",
    "    - Non-spacing characters like ZWJ/ZWNL\n",
    "    - Multiple representations of Nukta based characters \n",
    "    - Multiple representations of two part dependent vowel signs\n",
    "    - Typing inconsistencies: e.g. use of pipe (|) for poorna virama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "क़ क़\n",
      "Length before normalization: 4\n",
      "Length after normalization: 5\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "\n",
    "input_text=u\"\\u0958 \\u0915\\u093c\"\n",
    "remove_nuktas=False\n",
    "factory=IndicNormalizerFactory()\n",
    "normalizer=factory.get_normalizer(\"hi\",remove_nuktas)\n",
    "output_text=normalizer.normalize(input_text)\n",
    "\n",
    "print output_text\n",
    "print 'Length before normalization: {}'.format(len(input_text))\n",
    "print 'Length after normalization: {}'.format(len(output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Conversion\n",
    "\n",
    "Convert from one Indic script to another. This is a simple script which exploits the fact that Unicode points of various Indic scripts are at corresponding offsets from the base codepoint for that script. The following scripts are supported:\n",
    "\n",
    "_Devanagari(Hindi,Marathi,Sanskrit,Konkani,Sindhi,Nepali), Assamese, Bengali, Oriya, Gujarati, Gurumukhi (Punjabi), Sindhi, Tamil, Telugu, Kannada, Malayalam_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਰਾਜਸ੍ਥਾਨ\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "input_text=u'राजस्थान'\n",
    "print UnicodeIndicTransliterator.transliterate(input_text,\"hi\",\"pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Romanization\n",
    "\n",
    "Convert script text to Roman text in the ITRANS notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rAjasthAna\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "\n",
    "input_text=u'राजस्थान'\n",
    "lang='hi'\n",
    "\n",
    "\n",
    "print ItransTransliterator.to_itrans(input_text,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicization (ITRANS to Indic Script)\n",
    "\n",
    "Let's call conversion of ITRANS-transliteration to an Indic script as **Indicization**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पितॣन्\n",
      "92a\n",
      "93f\n",
      "924\n",
      "963\n",
      "928\n",
      "94d\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "\n",
    "\n",
    "# input_text=u'rajasthAna'\n",
    "input_text=u'pitL^In'\n",
    "lang='hi'\n",
    "x=ItransTransliterator.from_itrans(input_text,lang)\n",
    "print x\n",
    "for y in x:\n",
    "    print '{:x}'.format(ord(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Query Script Information\n",
    "\n",
    "Indic scripts have been designed keeping phonetic principles in nature and the design and organization of the scripts makes it easy to obtain phonetic information about the characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is vowel?:  False\n",
      "Is consonant?:  True\n",
      "Is velar?:  True\n",
      "Is palatal?:  False\n",
      "Is aspirated?:  False\n",
      "Is unvoiced?:  True\n",
      "Is nasal?:  False\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.langinfo import *\n",
    "\n",
    "c=u'क'\n",
    "lang='hi'\n",
    "\n",
    "print 'Is vowel?:  {}'.format(is_vowel(c,lang))\n",
    "print 'Is consonant?:  {}'.format(is_consonant(c,lang))\n",
    "print 'Is velar?:  {}'.format(is_velar(c,lang))\n",
    "print 'Is palatal?:  {}'.format(is_palatal(c,lang))\n",
    "print 'Is aspirated?:  {}'.format(is_aspirated(c,lang))\n",
    "print 'Is unvoiced?:  {}'.format(is_unvoiced(c,lang))\n",
    "print 'Is nasal?:  {}'.format(is_nasal(c,lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Word Segmentation\n",
    "\n",
    "Unsupervised morphological analysers for various Indian language. Given a word, the analyzer returns the componenent morphemes. \n",
    "The analyzer can recognize inflectional and derivational morphemes. \n",
    "\n",
    "The following languages are supported:\n",
    "\n",
    "_Hindi, Punjabi, Marathi, Konkani, Gujarati, Bengali, Kannada, Tamil, Telugu, Malayalam_\n",
    "\n",
    "Support for more languages will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named morfessor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ae64fa52c6b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mindicnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munsupervised_morph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mindicnlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munsupervised_morph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupervisedMorphAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anoop/src/python/indic_nlp_library/src/indicnlp/morph/unsupervised_morph.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmorfessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mindicnlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlanginfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mindicnlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named morfessor"
     ]
    }
   ],
   "source": [
    "from indicnlp.morph import unsupervised_morph \n",
    "from indicnlp import common\n",
    "\n",
    "analyzer=unsupervised_morph.UnsupervisedMorphAnalyzer('mr')\n",
    "\n",
    "indic_string=u'आपल्या हिरड्यांच्या आणि दातांच्यामध्ये जीवाणू असतात .'\n",
    "\n",
    "analyzes_tokens=analyzer.morph_analyze_document(indic_string.split(' '))\n",
    "\n",
    "for w in analyzes_tokens: \n",
    "    print w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hi\":[\"नूप , रेटिश काल फोन पार बाट करेंगे\"]}\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "from django.utils.encoding import * \n",
    "from django.utils.http import * \n",
    "\n",
    "text=iri_to_uri(urlquote('anoop, ratish kal fone par baat karenge'))\n",
    "url=u'http://www.cfilt.iitb.ac.in/indicnlpweb/indicnlpws/transliterate_bulk/en/hi/{}/statistical'.format(text)\n",
    "\n",
    "response=urllib2.urlopen(url).read()\n",
    "print response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tokenization \n",
    "\n",
    "A trivial tokenizer which just tokenizes on the punctuation boundaries. This also includes punctuations for the Indian language scripts (the purna virama and the deergha virama). It returns a list of tokens.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String: अनूप,अनूप?।फोन\n",
      "Tokens: \n",
      "अनूप\n",
      ",\n",
      "अनूप\n",
      "?\n",
      "।\n",
      "फोन\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.tokenize import indic_tokenize  \n",
    "\n",
    "indic_string=u'अनूप,अनूप?।फोन'\n",
    "\n",
    "print u'Input String: {}'.format(indic_string)\n",
    "print u'Tokens: '\n",
    "for t in indic_tokenize.trivial_tokenize(indic_string): \n",
    "    print t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
